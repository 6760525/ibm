{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# AI Workflow Capstone - AAVAIL - **Part 3 - Model Production**\n",
    "\n",
    "Student: `Alexey Tyurin`<br>\n",
    "Date: `1/18/2024`\n",
    "<hr>\n",
    "\n",
    "### Outline\n",
    "\n",
    "1. Build a draft version of an API with train, predict, and logfile endpoints.\n",
    "2. Using Docker, bundle your API, model, and unit tests.\n",
    "3. Using test-driven development iterate on your API in a way that anticipates scale, load, and drift.\n",
    "4. Create a post-production analysis script that investigates the relationship between model performance and the business metric.\n",
    "5. Articulate your summarized findings in a final report.\n",
    "\n",
    "At a higher level you are being asked to:\n",
    "\n",
    "1. Ready your model for deployment\n",
    "2. Query your API with new data and test your monitoring tools\n",
    "3. Compare your results to the gold standard\n",
    "\n",
    "\n",
    "### Create a flask API\n",
    "\n",
    "The API performs the train, predict and logfile tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will be using the data from the previous notebook to create different models and compare them to see which one is the best\n",
    "\n",
    "# Importing the libraries\n",
    "from utils_model import * #model_train, model_load, model_predict\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "MODEL_DIR = os.path.join(\".\", \"models\")\n",
    "LOG_DIR = os.path.join(\".\", \"logs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading time series data from files\n",
      "Training Models\n",
      "Country: all ...best model: K Neighbors Regressor, rmse = 13,768.44, R^2 = 97.3%\n",
      "Country: eire ...best model: Random Forest Regressor, rmse = 2,135.77, R^2 = 63.3%\n",
      "Country: france ...best model: Random Forest Regressor, rmse = 347.85, R^2 = 87.5%\n",
      "Country: germany ...best model: K Neighbors Regressor, rmse = 413.21, R^2 = 84.2%\n",
      "Country: hong_kong ...best model: Random Forest Regressor, rmse = 683.21, R^2 = 84.1%\n",
      "Country: netherlands ...best model: K Neighbors Regressor, rmse = 108.98, R^2 = 90.0%\n",
      "Country: norway ...best model: Ada Boosting Regressor, rmse = 9,049.62, R^2 = -1256.9%\n",
      "Country: portugal ...best model: Random Forest Regressor, rmse = 166.85, R^2 = 98.3%\n",
      "Country: singapore ...best model: Ada Boosting Regressor, rmse = 2,094.88, R^2 = -114.7%\n",
      "Country: spain ...best model: K Neighbors Regressor, rmse = 226.97, R^2 = 94.1%\n",
      "Country: united_kingdom ...best model: K Neighbors Regressor, rmse = 17,045.27, R^2 = 95.5%\n"
     ]
    }
   ],
   "source": [
    "model_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Models\n",
      "dict_keys(['all', 'eire', 'france', 'germany', 'hong_kong', 'netherlands', 'norway', 'portugal', 'singapore', 'spain', 'united_kingdom'])\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "all_models = model_load(model_dir='models')\n",
    "print(all_models.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Prediction for 2018-01-05\n",
      "... loading time series data from files\n",
      "Loading Models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'y_pred': array([183479.624])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'year': 2018,\n",
    "         'month': 1,\n",
    "         'day': 5,\n",
    "         'country': 'all',\n",
    "         'dev': True,\n",
    "         'verbose': True}\n",
    "\n",
    "model_predict(**query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"y_pred\":[183479.62399999998]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## API predict\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "query = {'year': 2018,\n",
    "         'month': 1,\n",
    "         'day': 5,\n",
    "         'country': 'all',\n",
    "         'dev': 'True',\n",
    "         'verbose': 'True'}\n",
    "\n",
    "port = 8080\n",
    "r = requests.post(f'http://localhost:{port}/predict', json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API train\n",
    "query = {'dev': 'True',\n",
    "         'verbose': 'True'}\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/train'.format(port),json=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logfile': 'test-train-2024-1.log'}\n"
     ]
    }
   ],
   "source": [
    "## API logging\n",
    "query = {'env': 'test',\n",
    "         'tag': 'train',\n",
    "         'year': '2024',\n",
    "         'month': '1',\n",
    "         'verbose': 'True'}\n",
    "\n",
    "port = 8080\n",
    "r = requests.post('http://localhost:{}/logging'.format(port),json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unit Tests\n",
    "\n",
    "The unit tests are usually organized as a suite and return objective evidence, in the form of a boolean value, which is a key element that enables workflow automation. The boolean value indicates whether or not each and every part of the software that was tested performed as expected. Much like data ingestion, the idea is to have the necessary components of a task bundled under a single script. In this case it will be called `run-tests.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
