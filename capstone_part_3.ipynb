{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# AI Workflow Capstone - AAVAIL - **Part 3 - Model Production**\n",
    "\n",
    "Student: `Alexey Tyurin`<br>\n",
    "Date: `1/18/2024`\n",
    "<hr>\n",
    "\n",
    "### Outline\n",
    "\n",
    "1. Build a draft version of an API with train, predict, and logfile endpoints.\n",
    "2. Using Docker, bundle your API, model, and unit tests.\n",
    "3. Using test-driven development iterate on your API in a way that anticipates scale, load, and drift.\n",
    "4. Create a post-production analysis script that investigates the relationship between model performance and the business metric.\n",
    "5. Articulate your summarized findings in a final report.\n",
    "\n",
    "At a higher level you are being asked to:\n",
    "\n",
    "1. Ready your model for deployment\n",
    "2. Query your API with new data and test your monitoring tools\n",
    "3. Compare your results to the gold standard\n",
    "\n",
    "\n",
    "### Create a flask API\n",
    "\n",
    "The API performs the train, predict and logfile tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we will be using the data from the previous notebook to create different models and compare them to see which one is the best\n",
    "\n",
    "# Importing the libraries\n",
    "from model import model_train, model_load, model_predict\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading ts data from files\n",
      "... saving model: models\\sl-all-0_1.joblib\n",
      "... saving model: models\\sl-eire-0_1.joblib\n",
      "... saving model: models\\sl-france-0_1.joblib\n",
      "... saving model: models\\sl-germany-0_1.joblib\n",
      "... saving model: models\\sl-hong_kong-0_1.joblib\n",
      "... saving model: models\\sl-netherlands-0_1.joblib\n",
      "... saving model: models\\sl-norway-0_1.joblib\n",
      "... saving model: models\\sl-portugal-0_1.joblib\n",
      "... saving model: models\\sl-singapore-0_1.joblib\n",
      "... saving model: models\\sl-spain-0_1.joblib\n",
      "... saving model: models\\sl-united_kingdom-0_1.joblib\n"
     ]
    }
   ],
   "source": [
    "model_train('cs-train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading ts data from files\n",
      "all_data:  all, eire, france, germany, hong_kong, netherlands, norway, portugal, singapore, spain, united_kingdom\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "all_data, all_models = model_load(data_dir='cs-train')\n",
    "print(\"all_data: \", \", \".join(all_models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## API train\n",
    "query = {'dev': 'True',\n",
    "         'verbose': 'True'}\n",
    "\n",
    "port = 8080\n",
    "r = requests.post(f'http://localhost:{port}/train', json=query)\n",
    "pritn(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logfile': 'test-train-2020-5.log'}\n"
     ]
    }
   ],
   "source": [
    "## API logging\n",
    "query = {'env': 'test',\n",
    "         'type': 'train',\n",
    "         'year': '2020',\n",
    "         'month': '5'}\n",
    "\n",
    "port = 8080\n",
    "r = requests.post(f'http://localhost:{port}/logging', json=query)\n",
    "response = literal_eval(r.text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [500]>\n"
     ]
    }
   ],
   "source": [
    "## API predict\n",
    "import requests\n",
    "from ast import literal_eval\n",
    "\n",
    "query = {'year': '2018',\n",
    "         'month': '1',\n",
    "         'day': '5',\n",
    "         'country': 'Total',\n",
    "         'dev': 'True',\n",
    "         'verbose': 'True'}\n",
    "\n",
    "port = 8080\n",
    "r = requests.post(f'http://localhost:{port}/predict', json=query)\n",
    "#response = literal_eval(r.text)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Unit Tests\n",
    "\n",
    "The unit tests are usually organized as a suite and return objective evidence, in the form of a boolean value, which is a key element that enables workflow automation. The boolean value indicates whether or not each and every part of the software that was tested performed as expected. Much like data ingestion, the idea is to have the necessary components of a task bundled under a single script. In this case it will be called `run-tests.py`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
